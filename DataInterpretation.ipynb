{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug pandas not importing\n",
    "import sys\n",
    "print(sys.executable)\n",
    "#taking the information from the line above -- directly import pandas module in here -- this is some wizardry\n",
    "! /Users/Amy/anaconda3/python.exe -m pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 - import data into juypter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 - Use matplotlib to make a barplot of the data and check for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data\n",
    "df = pd.read_csv(\"DESEQ2NormalizedData.csv\", index_col=0)\n",
    "df.head()\n",
    "\n",
    "df.shape #returns dimensions of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#swaps the x and y values\n",
    "data = df.transpose()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(plt.style.available) list of available displays\n",
    "\n",
    "plt.style.use('fast')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "fig.set_size_inches(50, 10.5)\n",
    "\n",
    "plt.boxplot(data)\n",
    "plt.xticks(rotation = 90)\n",
    "\n",
    "plt.xlabel(\"Samples\", size = 32)\n",
    "plt.ylabel(\"Expression\", size = 32)\n",
    "plt.title(\"Normalization Barplot\", size = 38)\n",
    "\n",
    "x_ticks = list(df.index)\n",
    "ax.set_xticklabels(x_ticks)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 - remove outliers; none exist\n",
    "Step 4 - find library to convert gene ids into gene symbols - perhaps an R package or online resource?\n",
    "\n",
    "Possible resource - https://www.researchgate.net/post/How-to-map-probe-ID-with-gene-symbol-in-GEO-dataset\n",
    "Dataset - https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE125583\n",
    "Official gene symbols (I think) - https://www.genenames.org/tools/search/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps for 4: \n",
    "\n",
    "Utilize API provided by NCBI to scrape gene information from data\n",
    "\n",
    "Source: https://www.ncbi.nlm.nih.gov/home/develop/api/\n",
    "\n",
    "Entrez appears to be the most promising since it offers databases for genes which is the one we're targeting.\n",
    "\n",
    "Sample of what we want to achieve: https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=gene&id=100093631\n",
    "^From that, if I get the <Name> section of the gene and combine them together, then it's all set\n",
    "\n",
    "Always returns xml file. \n",
    "\n",
    "Template: https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=gene&id=[insert custom id parsed from data here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"test\" function to grab gene information\n",
    "\n",
    "#need to write a script that automatically runs through the urls for me\n",
    "import requests as r\n",
    "\n",
    "# genes = \"100093631\"\n",
    "#response = r.get(f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=gene&id={genes}\") #created a template literal with variable that functions as the value\n",
    "#print(response)\n",
    "\n",
    "query = {'db': 'gene', 'id': '100093631,1,2,3,4,5,6,7,8,9'}\n",
    "response = r.get('https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?', params=query)\n",
    "\n",
    "#parse the xml file\n",
    "import xml.etree.ElementTree as ET\n",
    "root = ET.fromstring(response.content)\n",
    "print(root[0][1][0].text) # <- this gives me the first one... woot!\n",
    "print(root[0][2][0].text) # <- this is the next one!\n",
    "print(root[0][3][0].text) # <- this gives the third one!\n",
    "print(root[0][4][0].text) # <- this gives the fourth one!\n",
    "print(root[0][5][0].text) # <- this gives the fifth one!\n",
    "print(root[0][6][0].text) # <- this gives the sixth one!\n",
    "print(root[0][7][0].text) # <- this gives the seventh one!\n",
    "print(root[0][8][0].text) # <- this gives the eighth one!\n",
    "print(root[0][9][0].text) # <- this gives the ninth (nineth) one!\n",
    "print(root[0][10][0].text) # <- this gives the tenth one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: \n",
    "- Downloading Document Summaries: https://www.ncbi.nlm.nih.gov/books/NBK25500/#chapter1.Downloading_Document_Summaries\n",
    "- API Requests tutorial: https://www.nylas.com/blog/use-python-requests-module-rest-apis/\n",
    "- Using ElementTree: https://www.edureka.co/blog/python-xml-parser-tutorial/#findingelements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab gene ids from csv file and pasted it into ids.txt\n",
    "# Goal is to eventually create a dictionary that links the gene id with the gene symbol\n",
    "\n",
    "import time  # will be useful when trying to puase the program for a while\n",
    "import csv\n",
    "file = open('DESeq2NormalizedData.csv')\n",
    "csvreader = csv.reader(file)\n",
    "header = []\n",
    "header = next(csvreader) \n",
    "# header contains all of the items in the first row\n",
    "# remove the first one since that's just a ''\n",
    "header = header[1:]\n",
    "\n",
    "# write into the file and then drag it onto the other row later on\n",
    "with open('key.csv', 'w', newline=\"\") as file:\n",
    "    csvwriter = csv.writer(file)  # create csvwriter object\n",
    "    csvwriter.writerow(header)  # write the header (aka the gene ids)\n",
    "\n",
    "    # have to get the data before I write it\n",
    "    data = []\n",
    "    tempIDHolder = []\n",
    "    # create a dictionary that links the gene id with the gene symbol\n",
    "    for id in header:\n",
    "        tempIDHolder.append(id)\n",
    "        if (len(tempIDHolder) >= 10):\n",
    "        # request a downloadable summary, etc.\n",
    "            # first convert the tempIDHolder into actual id value\n",
    "            id = tempIDHolder[0]\n",
    "            counter = 0\n",
    "            for item in tempIDHolder:\n",
    "                if counter == 0:\n",
    "                    counter += 1\n",
    "                else :\n",
    "                    id = id + ',' + item # hopefully this gets everything?\n",
    "            # print(id)\n",
    "            query = {'db': 'gene', 'id': id}\n",
    "            response = r.get(\n",
    "                'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?', params=query)\n",
    "            root = ET.fromstring(response.content)\n",
    "            data.append(root[0][1][0].text)\n",
    "            data.append(root[0][2][0].text)\n",
    "            data.append(root[0][3][0].text)\n",
    "            data.append(root[0][4][0].text)\n",
    "            data.append(root[0][5][0].text)\n",
    "            data.append(root[0][6][0].text)\n",
    "            data.append(root[0][7][0].text)\n",
    "            data.append(root[0][8][0].text)\n",
    "            data.append(root[0][9][0].text)\n",
    "            data.append(root[0][10][0].text)\n",
    "            # make it pause or else the API will yell at me (it was like 3 requests per second if I remember correctly)\n",
    "            # make it sleep for half a second... therefore it should be like 2 requests per second\n",
    "            # print(root[0][1][0].text)\n",
    "            time.sleep(.5)\n",
    "            # reset tempIDHolder\n",
    "            tempIDHolder.clear()\n",
    "\n",
    "    csvwriter.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the gene ids that I am still missing (since I did it by factors of 10) and manually modify the key.csv\n",
    "print(len(header))\n",
    "# result: 16232, so that means I only have to get two, phew!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double checking my computer's capability to handle large array sizes - source: https://stackoverflow.com/questions/855191/how-big-can-a-python-list-get#:~:text=According%20to%20the%20source%20code,PY_SSIZE_T_MAX%2Fsizeof(PyObject*)%20.&text=On%20a%20regular%2032bit%20system,bit%20system%20is%20536%2C870%2C912%20elements.\n",
    "import six\n",
    "print(six.MAXSIZE)\n",
    "# result: 9223372036854775807, so yeah it should be fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources:\n",
    "- Manipulating csv file to get just the header: https://www.analyticsvidhya.com/blog/2021/08/python-tutorial-working-with-csv-file-for-data-science/\n",
    "- How to manipulate python dictionaries: https://www.geeksforgeeks.org/python-dictionary/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace DF ids with Gene Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import conversion library\n",
    "translate = pd.read_csv(\"key.csv\")\n",
    "translate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colNames = list(translate.iloc[0, :])\n",
    "\n",
    "DataTot = df.set_axis(colNames, axis=1, inplace=False)\n",
    "DataTot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select genes to focus on\n",
    "\n",
    "Genes extracted from DE here: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE132651"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used a Google script and ripped off an array and just copy pasted it here. Is it clean? Haha no\n",
    "gene_list = [\"MMP1\", \"TFPI2\", \"ANGPT2\", \"SULF1\", \"SULF1\", \"FABP4\", \"ANGPT2\", \"IL1RL1\", \"TFPI2\", \"ADGRF5\", \"FST\", \"VAMP8\", \"SULF1\", \"MRC1\", \"TOX\", \"BASP1\", \"EMCN\", \"LYVE1\", \"COL4A5\", \"MMP10\", \"ANKRD1\", \"TACSTD2\", \"GULP1\", \"RASGRP3\", \"LEPROT///LEPR\", \"GULP1\", \"NUPR1\", \"PBK\", \"SULT1E1\", \"ADGRF5\", \"PROS1\", \"EPB41L3\", \"ALDH1A1\", \"PFN2\", \"FABP5\", \"TSPAN13\", \"FGF13\", \"LIMCH1\", \"GMFG\", \"IL1R1\", \"PDE2A\", \"SRSF6\", \"TGFB2\", \"LYN\", \"CLU\", \"LBH\", \"MIR6787///SLC16A3\", \"EPB41L3\", \"CHST15\", \"ANOS1\", \"TIMP3\", \"RRM2\", \"RGCC\", \"MIR6787///SLC16A3\", \"EPB41L3\", \"FST\", \"HSD17B2\", \"GULP1\", \"THSD7A\", \"SLC6A15\", \"LTBP1\", \"COL13A1\", \"LIMCH1\", \"KRT7\", \"ANXA3\", \"MAD2L1\", \"LAMP3\", \"DYSF\", \"SLC35F6///CENPA\", \"CLEC2B\", \"LDB2\", \"LTBP1\", \"LYVE1\", \"DKK1\", \"RPS4Y1\", \"SLIT2\", \"DPYSL3\", \"FBLN5\", \"NRP2\", \"CXCR4\", \"C10orf10\", \"CLU\", \"NRG1\", \"CSGALNACT1\", \"HJURP\", \"ASPM\", \"PLA2G4C\", \"ADIRF\", \"TOP2A\", \"BST2\", \"CD44\", \"HLA-B\", \"LIMCH1\", \"TGFB2\", \"DLGAP5\", \"SULT1B1\", \"SACS\", \"COL3A1\", \"HMMR\", \"LOC101930400///AKR1C2\", \"TIMP3\", \"IFI27\", \"BMP4\", \"NID1\", \"UCHL1\", \"NDC1\", \"SHCBP1\", \"LYN\", \"EMP3\", \"CCND2\", \"CCL15-CCL14///CCL14\", \"CDC20\", \"MAFB\", \"GPX3\", \"AURKA\", \"PTTG1\", \"RFC3\", \"BCAT1\", \"RBP1\", \"MEIS2\", \"CCNB1\", \"SH3BP5\", \"VCAM1\", \"CKS1B\", \"PRC1\", \"JUP\", \"GJA4\", \"NCAPG\", \"LYPD1\", \"BCHE\", \"TMEM140\", \"IGFBP2\", \"CCND2\", \"HOXA10-HOXA9///MIR196B///HOXA9\", \"AKR1C1\", \"TNFSF10\", \"PODXL\", \"IL13RA2\", \"SPC25\", \"UBE2S\", \"GYPC\", \"NDC80\", \"ABCG1\", \"CEP55\", \"EIF1AY\", \"GATA6\", \"GPRC5A\", \"PDPN\", \"TNFSF10\", \"CD36\", \"RELN\", \"CCNA2\", \"CSF2RB\", \"ANPEP\", \"CDK1\", \"GJA4\", \"MT1M\", \"TRPV2\", \"RRM2\", \"CLU\", \"GPX3\", \"TGFBR2\", \"CCNA1\", \"SMC2\", \"UBD///GABBR1\", \"TGFB2\", \"ADD3\", \"FHL1\", \"KIAA0101\", \"MELK\", \"SQRDL\", \"PIEZO2\", \"RRP15\", \"DEPDC1\", \"XIST\", \"TPD52\", \"SOX18\", \"OIP5\", \"MFAP2\", \"MPZL2\", \"TMPO\", \"CCNA2\", \"TPX2\", \"TRIP13\", \"PCDH7\", \"PLPP3\", \"PCNA\", \"PTPRN2\", \"POSTN\", \"NRP2\", \"BACE2\", \"NPTX2\", \"DKK3\", \"PLOD2\", \"TGFBR2\", \"SPRY1\", \"HSPD1\", \"MT1X\", \"KIF20A\", \"CENPN\" ]\n",
    "\n",
    "len(gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see which ones match\n",
    "colNames = list(DataTot.columns)\n",
    "\n",
    "geneOverlap = list(set(gene_list).intersection(colNames))\n",
    "len(geneOverlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectDf = DataTot.loc[:, geneOverlap[0:100]]\n",
    "# create an excel file of the dataframe\n",
    "# selectDf.to_excel(\"completeDataset.xlsx\")\n",
    "selectDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 70/30 split\n",
    "shuffledData = selectDf.sample(frac=1, random_state=42)\n",
    "shuffledData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = shuffledData.shape\n",
    "splitThreshold = round(x*.7)\n",
    "\n",
    "TrainData = shuffledData.iloc[0:splitThreshold, :]\n",
    "TestData = shuffledData.iloc[splitThreshold:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input and output set (50/50) for now, but may change later\n",
    "# randomize columns\n",
    "tempShuffleDf = TrainData.T\n",
    "tempShuffleDf = tempShuffleDf.sample(frac=1, random_state=500)\n",
    "TrainData = tempShuffleDf.T\n",
    "tempShuffleDf = TestData.T\n",
    "tempShuffleDf = tempShuffleDf.sample(frac=1, random_state=500)\n",
    "TestData = tempShuffleDf.T\n",
    "\n",
    "# split the data\n",
    "x_train = TrainData.iloc[:, 0:50]\n",
    "y_train = TrainData.iloc[:, 50:]\n",
    "\n",
    "x_test = TestData.iloc[:, 0:50]\n",
    "y_test = TestData.iloc[:, 50:]\n",
    "\n",
    "# print(tempShuffleDf.T) #note .T transposes/reverses the data\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Random Forest\n",
    "\n",
    "I used classification first simply because it was the first one lol... future Amy here. Turns out I should be using regression instead or else I run into a 'continuous-multioutput' error... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing sklearn (and pandas again) because my computer doesn't recognize it\n",
    "! /Users/Amy/anaconda3/python.exe -m pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml import\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(df.iloc[0, 0])\n",
    "print('---------')\n",
    "print(selectDf.head(0).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model and train\n",
    "reg = RandomForestRegressor(n_estimators=400, random_state=42)\n",
    "reg.fit(x_train, y_train) #nah this should work... but it just doesn't quite match the actual thing nicely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.shape, y_pred.shape) #wtf y_pred is already a numpyarray whereas y_test is the one that isn't\n",
    "ny_test = y_test.to_numpy()\n",
    "print(y_pred[:, 0]) #only the predicted values for the first gene\n",
    "print(ny_test[:, 0]) #only the actual values for the first gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame()\n",
    "df2['Predicted'] = y_pred[:, 0]\n",
    "df2['Actual'] = ny_test[:, 0]\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred[:, 0].tolist())\n",
    "print(ny_test[:, 0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimental function to find the percent difference error\n",
    "predicted = [7.090191573100002, 7.458117004670004, 8.600444416470005, 7.788848798920004, 8.40825437213, 7.020327500409999, 8.818133271350002, 7.8266646558799975, 6.9378079908900006, 6.872748400490001, 7.506390345189996, 8.676429359800004, 8.554343255570004, 7.166067258440004, 8.747529485299998, 7.968960927520005, 7.452849082630001, 7.761508404270005, 8.320082494520001, 7.971978045290004, 6.697892382179999, 8.949659341020002, 8.5578288482, 8.959041092180001, 8.720058047870003, 9.099238304330001, 6.597845043869999, 8.771403687159996, 8.97738436032, 9.337057343459998, 8.615097380400004, 8.379626407890001, 6.837338580420003, 6.728788978850002, 6.72586007986, 8.569162017440004, 8.760991396020003, 6.398245022990002, 8.775553368840006, 8.599701066330004, 6.706699092590001, 7.119638600939998, 7.276036668970002, 8.70239843987, 7.404154973279999, 8.162479427099996, 6.613187798319999, 8.779790491420004, 8.06791024708, 7.6901312955200005, 6.943329752419999, 7.805397315200001, 7.597572052499999, 7.180362284900005, 8.814388118280004, 8.770979079269997, 8.452227193040002, 8.525045438540001, 7.466116578500001, 6.994484173059999, 7.585299090140003, 8.753943669680002, 8.870920817819997, 7.499310703240001, 9.286605262920002, 7.215856328890001, 9.01209597088, 8.669163431630004, 7.186433201240003, 7.302876306980005, 8.488108625080002, 7.504864159039996, 7.927865327730001, 6.44979854136, 7.310411780489999, 8.626030034680007, 8.696088902549997, 7.079432411410002, 8.071684938880002, 8.670569142679998, 7.816587408060005, 8.141853975380002, 8.353289437620003, 8.788246874929996, 8.285601362710002, 8.440699586870002, 8.812269140540002]\n",
    "actual = [6.897812565, 7.338213509, 8.702359981, 7.948689744, 8.542811765, 6.837543279, 9.269233796, 8.330263567, 6.537387668, 7.477668772, 7.705141327, 8.388086398, 9.047330902, 7.177687891, 10.07887491, 9.96112512, 8.251808157, 6.519026254, 8.593129162, 8.215544999, 7.127999315, 10.67614923, 8.178851803, 9.602720917, 8.661232602, 9.332002144, 5.497343234, 8.824692683, 9.209058607, 10.23649005, 9.169253621, 8.778581143, 7.461903599, 5.902414739, 6.728518061, 9.278008069, 8.990431014, 6.179569244, 9.553214953, 9.109478527, 5.240724147, 6.385636127, 7.785670875, 7.881095765, 7.66056203, 7.875984985, 6.533125215, 8.506735274, 8.547510836, 7.644934135, 7.248378845, 8.506008575, 7.605692603, 7.694407888, 9.458641893, 8.627903977, 9.76776567, 8.207819731, 7.342463366, 7.43472634, 8.535281792, 8.828590939, 9.350347751, 7.530876833, 9.484744463, 7.558263108, 9.522007793, 9.427759537, 8.263312582, 7.284029873, 8.352555076, 6.142537446, 8.535022869, 5.554148673, 7.672479957, 8.185338403, 8.421832893, 7.733339952, 9.832547685, 8.320524407, 8.941760952, 9.285487465, 9.122246483, 8.718260929, 8.794853801, 8.622207487, 10.1410804]\n",
    "\n",
    "# find the percent difference of each value, add them up and divide by 87 to find average percent difference\n",
    "averagePercentDifference = 0\n",
    "for index in range(87):\n",
    "    # percent difference equation: |pred-actual|/actual\n",
    "    averagePercentDifference += abs(predicted[index]-actual[index])/actual[index] * 100\n",
    "# divided by 87\n",
    "averagePercentDifference /= 87\n",
    "\n",
    "averagePercentDifference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining the previous steps to check reliability and run tests repeatedly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this test multiple times... because I am not convinced of the results\n",
    "import pandas as pd\n",
    "import random\n",
    "# ml import\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "averagePercentDifference = 0\n",
    "numTrials = 50\n",
    "for i in range(numTrials):\n",
    "    # convert the completeDataset.xlsx into a pandas dataframe because I don't want to redo the previous steps over and over again every time I reopen the notebook\n",
    "    selectDf = pd.read_excel(\"completeDataset.xlsx\", index_col=0)\n",
    "\n",
    "    randNum = random.randrange(500)\n",
    "    # create 70/30 split of training and testing datasets\n",
    "    shuffledData = selectDf.sample(frac=1, random_state=42)\n",
    "\n",
    "    x, y = shuffledData.shape\n",
    "    splitThreshold = round(x*.7)\n",
    "\n",
    "    TrainData = shuffledData.iloc[0:splitThreshold, :]\n",
    "    TestData = shuffledData.iloc[splitThreshold:, :]\n",
    "\n",
    "    # create input and output set (50/50) for now, but may change later\n",
    "    # randomize columns\n",
    "    tempShuffleDf = TrainData.T\n",
    "    tempShuffleDf = tempShuffleDf.sample(frac=1, random_state=randNum)\n",
    "    TrainData = tempShuffleDf.T\n",
    "    tempShuffleDf = TestData.T\n",
    "    tempShuffleDf = tempShuffleDf.sample(frac=1, random_state=randNum)\n",
    "    TestData = tempShuffleDf.T\n",
    "\n",
    "    splitIndex = 80 #first {splitIndex} will be used as input variables\n",
    "\n",
    "    # split the data\n",
    "    x_train = TrainData.iloc[:, 0:splitIndex]\n",
    "    y_train = TrainData.iloc[:, splitIndex:]\n",
    "\n",
    "    x_test = TestData.iloc[:, 0:splitIndex]\n",
    "    y_test = TestData.iloc[:, splitIndex:]\n",
    "\n",
    "    # instantiate model and train\n",
    "    reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    reg.fit(x_train, y_train)\n",
    "\n",
    "    # actually train the model\n",
    "    y_pred = reg.predict(x_test)\n",
    "    ny_test = y_test.to_numpy()\n",
    "\n",
    "    x, y = y_pred.shape\n",
    "    for row in range(x):\n",
    "        for col in range(y):\n",
    "            # calculate the percent difference for the value\n",
    "            averagePercentDifference += abs(y_pred[row][col] - ny_test[row][col])/ny_test[row][col]\n",
    "    averagePercentDifference /= (x*y)\n",
    "\n",
    "averagePercentDifference*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning the hyperparameters - source: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print('Parameters currently in use: \\n')\n",
    "pprint(reg.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the article it states that the most important hyperparameters is the n_estimators (# of trees), number of features (max_features)\n",
    "# possible adjustments to be made and explanation\n",
    "'''\n",
    "n_estimators = number of trees in the foreset\n",
    "max_features = max number of features considered for splitting a node\n",
    "max_depth = max number of levels in each decision tree\n",
    "min_samples_split = min number of data points placed in a node before the node is split\n",
    "min_samples_leaf = min number of data points allowed in a leaf node\n",
    "bootstrap = method for sampling data points (with or without replacement)\n",
    "'''\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)\n",
    "# total of 4320 possible settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Search Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(x_train, y_train)\n",
    "# rf_pred = rf_random.predict(x_test) # something new I added... maybe check it out later\n",
    "\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    errors = errors.to_numpy()\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors))) #idk if this works as intended ngl\n",
    "    print('Accuracy = {:0.2f}%.'.format(np.mean(accuracy.to_list())))\n",
    "    \n",
    "    return accuracy\n",
    "# base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "# base_model.fit(x_train, y_train)\n",
    "# base_accuracy = evaluate(base_model, x_test, y_test)\n",
    "\n",
    "base_accuracy = evaluate(reg, x_test, y_test)\n",
    "\n",
    "print()\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [50, 100, 150], #why is it these values... idk myself ngl\n",
    "    'max_features': [13, 15, 17, 19, 21], #idk for these values either tbh... maybe research later\n",
    "    'min_samples_leaf': [1],\n",
    "    'min_samples_split': [2],\n",
    "    'n_estimators': [100, 200, 300, 400, 500]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# fit the grid search to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# multidimensional RMSE calculation\n",
    "def MDRMSE(predy, testy): # multi-dimensional RMSE\n",
    "    # rows are samples\n",
    "    # columns are genes\n",
    "    # iterate through each sample and take gene distribution calculate RMSE and add to list\n",
    "\n",
    "    # should be iterating through every predicted y value instead, fixed it\n",
    "    x, y = predy.shape\n",
    "    allRMSE = []\n",
    "    \n",
    "    for col in range(y):\n",
    "        pred = predy.iloc[:, col]\n",
    "        test = testy.iloc[:, col]\n",
    "        rmse = mean_squared_error(test, pred)\n",
    "        allRMSE.append(rmse)\n",
    "    \n",
    "    # Calculate sum of list and divide by number of items\n",
    "    averageRMSE = sum(allRMSE)/len(allRMSE)\n",
    "    \n",
    "    # return the aggregated RMSE\n",
    "    return averageRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percent Difference Error\n",
    "\n",
    "def PDE(y_pred, y_test):\n",
    "    averagePercentDifference = 0\n",
    "    x, y = y_pred.shape\n",
    "    for row in range(x):\n",
    "        for col in range(y):\n",
    "            # calculate the percent difference for the value\n",
    "            averagePercentDifference += abs(y_pred[row][col] - y_test[row][col])/y_test[row][col]\n",
    "    averagePercentDifference /= (x*y)\n",
    "    return averagePercentDifference*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# more info about multioutput parameter: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html\n",
    "\n",
    "# R^2 function\n",
    "def R2_SCORE(y_pred, y_test, modelType):\n",
    "    if (modelType == 'FOREST'): # source: https://stats.stackexchange.com/questions/7357/manually-calculated-r2-doesnt-match-up-with-randomforest-r2-for-testing?noredirect=1&lq=1\n",
    "        return r2_score(y_test, y_pred, multioutput='variance_weighted')\n",
    "    elif (modelType == 'PLS'): # source: https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/regression-and-correlation/coefficient-of-determination-r-squared.html#:~:text=Solution,into%20the%20regression%20line%20equation.\n",
    "        return r2_score(y_test, y_pred)\n",
    "    else:\n",
    "        print(\"The only values accepted are \\'FOREST\\' and \\'PLS\\'.\")\n",
    "        return #can I not add a return here?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSerror = MDRMSE(pd.DataFrame(y_pred), y_test)\n",
    "percentError = PDE(y_pred, y_test.to_numpy())\n",
    "R2_1 = R2_SCORE(y_pred, y_test, 'FOREST')\n",
    "R2_2 = R2_SCORE(y_pred, y_test, 'PLS')\n",
    "\n",
    "print(\"Predicted values are all from initial \\\"Forest\\\" model\")\n",
    "print(\"Root Means Squared Error: \", end=\"\")\n",
    "print(RMSerror)\n",
    "print(\"Percent Difference Error: \", end=\"\")\n",
    "print(percentError)\n",
    "print(\"R2 SCORE - as a forest: \", end=\"\")\n",
    "print(R2_1)\n",
    "print(\"R2 SCORE - as a PLS: \", end=\"\")\n",
    "print(R2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Residual Plots to show Performance of Forest is Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def StackedResidualPlot(y_pred, y_test):\n",
    "    # conert to np array with try/except\n",
    "    ny_test = y_test.to_numpy() #what's with the try/except catch method used for?\n",
    "\n",
    "    # calculate the residuals by column (variable)\n",
    "    residual = y_pred - ny_test\n",
    "    # predicted y on x axis and residual on y axis\n",
    "    # go iteratively over row by row -- AKA sample by sample\n",
    "\n",
    "    numRows = 5\n",
    "    numCols = 4\n",
    "\n",
    "    f = plt.figure()\n",
    "    f, axes = plt.subplots(nrows = numRows, ncols = numCols, sharex = True, sharey = True, figsize=(25, 25))\n",
    "\n",
    "    # axis and title\n",
    "    f.suptitle('Residual Plots', fontsize=42)\n",
    "    f.supxlabel('Predicted Values', fontsize=38) # reference: https://stackoverflow.com/a/65135433/15073477\n",
    "    f.supylabel('Residual Values', fontsize=38)\n",
    "\n",
    "    for row in range(numRows):\n",
    "        for col in range(numCols):\n",
    "            axes[row][col].scatter(y_pred[row+col], residual[row+col], marker = \"o\") #c = getRand(100)\n",
    "            # create a horizontal line!!! - source: https://pythonguides.com/matplotlib-best-fit-line/\n",
    "            theta = np.polyfit(y_pred[row+col], residual[row+col], 1) # 1 represents the degree\n",
    "            y_line = theta[1] + theta[0] * y_pred[row+col] # it said theta[0] * X... not sure what X represents in my code\n",
    "            axes[row][col].plot(y_pred[row+col], y_line, 'r')\n",
    "\n",
    "    # add separate colorbar axes\n",
    "    # cbar_ax = f.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    # f.colorbar(axes[0][0], cax=cbar_ax)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "StackedResidualPlot(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Partial Least Squares Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another tutorial with cross validation: https://www.statology.org/partial-least-squares-in-python/\n",
    "\n",
    "# ml imports\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source/documentation: https://scikit-learn.org/stable/modules/generated/sklearn.cross_decomposition.PLSRegression.html\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "pls2 = PLSRegression(n_components=9)\n",
    "pls2.fit(x_train, y_train)\n",
    "\n",
    "pls2_y_pred = pls2.predict(x_test)\n",
    "\n",
    "pls2.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Partial Least Squares - Source: https://nirpyresearch.com/partial-least-squares-regression-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_pls_cv(X, y, n_comp):\n",
    "    # Define PLS object\n",
    "    pls = PLSRegression(n_components=n_comp) #should use nipals algorithm\n",
    "\n",
    "    # Cross-validation\n",
    "    y_cv = cross_val_predict(pls, X, y, cv=10)\n",
    "\n",
    "    # Calculate scores\n",
    "    r2 = r2_score(y, y_cv)\n",
    "    mse = mean_squared_error(y, y_cv)\n",
    "    \n",
    "    return (y_cv, r2, mse, rpd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with 30 components\n",
    "r2s = []\n",
    "mses = []\n",
    "x, y = y_train.shape\n",
    "xticks = np.arange(1, 21)\n",
    "for n_comp in xticks:\n",
    "    y_cv, r2, mse, rpd = optimise_pls_cv(x_train, y_train, n_comp)\n",
    "    r2s.append(r2)\n",
    "    mses.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mses\n",
    "def plot_metrics(vals, ylabel, objective):\n",
    "    with plt.style.context('ggplot'):\n",
    "        plt.plot(xticks, np.array(vals), '-v', color='blue', mfc='blue')\n",
    "        if objective=='min':\n",
    "            idx = np.argmin(vals)\n",
    "        else:\n",
    "            idx = np.argmax(vals)\n",
    "        plt.plot(xticks[idx], np.array(vals)[idx], 'P', ms=10, mfc='red')\n",
    "\n",
    "        plt.xlabel('Number of PLS components')\n",
    "        plt.xticks = xticks\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.title('PLS')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(mses, 'MSE', 'min')\n",
    "plot_metrics(r2s, 'R2', 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cv, r2, mse, rpd = optimise_pls_cv(x_test, y_test, 18) #18 depends on what the points of the previous code block show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Partial Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSerror = MDRMSE(pd.DataFrame(pls2_y_pred), y_test)\n",
    "percentError = PDE(pls2_y_pred, y_test.to_numpy())\n",
    "R2_1 = R2_SCORE(pls2_y_pred, y_test, 'FOREST')\n",
    "R2_2 = R2_SCORE(pls2_y_pred, y_test, 'PLS')\n",
    "\n",
    "print(\"Predicted values are all from initial \\\"PLS\\\" Regression\")\n",
    "print(\"Root Means Squared Error: \", end=\"\")\n",
    "print(RMSerror)\n",
    "print(\"Percent Difference Error: \", end=\"\")\n",
    "print(percentError)\n",
    "print(\"R2 SCORE - as a forest: \", end=\"\")\n",
    "print(R2_1)\n",
    "print(\"R2 SCORE - as a PLS: \", end=\"\")\n",
    "print(R2_2)\n",
    "\n",
    "# Note: should also consider using RASE for error as a comparison, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the results of the forest model are here:\n",
    "\n",
    "RMSerror = MDRMSE(pd.DataFrame(y_pred), y_test)\n",
    "percentError = PDE(y_pred, y_test.to_numpy())\n",
    "R2_1 = R2_SCORE(y_pred, y_test, 'FOREST')\n",
    "R2_2 = R2_SCORE(y_pred, y_test, 'PLS')\n",
    "\n",
    "print(\"Predicted values are all from initial \\\"Forest\\\" model\")\n",
    "print(\"Root Means Squared Error: \", end=\"\")\n",
    "print(RMSerror)\n",
    "print(\"Percent Difference Error: \", end=\"\")\n",
    "print(percentError)\n",
    "print(\"R2 SCORE - as a forest: \", end=\"\")\n",
    "print(R2_1)\n",
    "print(\"R2 SCORE - as a PLS: \", end=\"\")\n",
    "print(R2_2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "362fdda7da3efa61b889f6cffefb4889d609e1a921f385f43ea41e9845cf9c35"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
